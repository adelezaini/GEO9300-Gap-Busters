{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, normaltest\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "def adaptive_scaling(dataframe, target_column=None, scaling_method=\"individual\"):\n",
    "    \"\"\"\n",
    "    Scales the features in the dataframe based on the specified or adaptive scaling method.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): Input dataset.\n",
    "        target_column (str): Name of the target column to exclude from scaling.\n",
    "        scaling_method (str): Scaling method to use. Options are:\n",
    "            - \"individual\": Decide scaling per column based on distribution.\n",
    "            - \"minmax\": Use MinMaxScaler for all features.\n",
    "            - \"standard\": Use StandardScaler for all features.\n",
    "            - \"logminmax\": Apply log transformation followed by MinMaxScaler for all features.\n",
    "    Returns:\n",
    "        scaled_df (pd.DataFrame): Scaled dataset with the same columns as the input.\n",
    "        scaling_info (dict): Information about the scaling method used for each column.\n",
    "    \"\"\"\n",
    "    assert scaling_method in [\"individual\", \"minmax\", \"standard\", \"logminmax\"], \\\n",
    "        \"Invalid scaling_method. Choose from 'individual', 'minmax', 'standard', 'logminmax'.\"\n",
    "    \n",
    "    scaled_df = dataframe.copy()\n",
    "    scaling_info = {}\n",
    "    columns = [col for col in dataframe.columns if col != target_column]\n",
    "\n",
    "    for col in columns:\n",
    "        \n",
    "        print(f\"Processing column: {col}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        if scaled_df[col].isnull().any():\n",
    "            print(f\"Warning: Column '{col}' contains missing values. Imputing with median.\")\n",
    "            scaled_df[col].fillna(scaled_df[col].median(), inplace=True)\n",
    "\n",
    "        # Decide scaling method\n",
    "        if scaling_method == \"individual\":\n",
    "            skewness = skew(scaled_df[col])\n",
    "            _, p_value = normaltest(scaled_df[col])\n",
    "            print(f\"  Skewness: {skewness:.2f}, Normality test p-value: {p_value:.4f}\")\n",
    "            \n",
    "            if p_value > 0.05:  # Normally distributed\n",
    "                print(f\"  Applying StandardScaler (data is approximately normal).\")\n",
    "                scaler = StandardScaler()\n",
    "            elif skewness > 1 or skewness < -1:  # Highly skewed\n",
    "                print(f\"  Applying log transformation followed by MinMaxScaler (data is skewed).\")\n",
    "                scaled_df[col] = np.log1p(scaled_df[col] - scaled_df[col].min() + 1)\n",
    "                scaler = MinMaxScaler()\n",
    "            else:  # Mildly skewed or uniform\n",
    "                print(f\"  Applying MinMaxScaler (data is mildly skewed or uniform).\")\n",
    "                scaler = MinMaxScaler()\n",
    "        elif scaling_method == \"minmax\":\n",
    "            print(f\"  Applying MinMaxScaler (user-specified method).\")\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaling_method == \"standard\":\n",
    "            print(f\"  Applying StandardScaler (user-specified method).\")\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling_method == \"logminmax\":\n",
    "            print(f\"  Applying log transformation followed by MinMaxScaler (user-specified method).\")\n",
    "            scaled_df[col] = np.log1p(scaled_df[col] - scaled_df[col].min() + 1)\n",
    "            scaler = MinMaxScaler()\n",
    "        \n",
    "        # Apply scaling\n",
    "        scaled_values = scaler.fit_transform(scaled_df[col].values.reshape(-1, 1))\n",
    "        scaled_df[col] = scaled_values.flatten()\n",
    "        scaling_info[col] = {\n",
    "            \"method\": scaling_method if scaling_method != \"individual\" else type(scaler).__name__,\n",
    "        }\n",
    "        \n",
    "        if scaling_method == \"individual\":\n",
    "            scaling_info[col].update({\n",
    "                \"skewness\": skewness,\n",
    "                \"normality_p_value\": p_value,\n",
    "            })\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot non-scaled distribution\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(dataframe[col], bins=30, alpha=0.7, label='Non-Scaled')\n",
    "        plt.title(f'Non-Scaled Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot scaled distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(scaled_df[col], bins=30, alpha=0.7, label='Scaled')\n",
    "        plt.title(f'Scaled Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return scaled_df, scaling_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
